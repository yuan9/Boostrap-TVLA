{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, norm, t as tdist, ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup graphs\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tkr\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 3.5\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "# plt.rcParams['figure.dpi'] = 100;\n",
    "\n",
    "# numpy print format\n",
    "np.set_printoptions(linewidth=120, precision=4, suppress=False, formatter={'float': '{:5.3e}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "import util.tests as tests\n",
    "import util.dwdb_reader as io\n",
    "import util.func as f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load traces and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first sample point, split by classification (2 traces, c1 and c2)\n",
    "print(\"Reading traces\")\n",
    "dsr = io.dwdb_reader(r'FP_db_small/log.dwdb', r'FP_db_small')\n",
    "data_batch, meta_batch = dsr.read_batch(10)\n",
    "print(\"Done\")\n",
    "\n",
    "pt_range = slice(2,4)\n",
    "data_batch2, meta_batch2 = data_batch[pt_range], meta_batch[pt_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert traces to numpy\n",
    "traces_np = np.asarray(data_batch2)\n",
    "traces_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract classifiers, convert to numpy\n",
    "meta_prep = [m['other'].split() for m in meta_batch2]\n",
    "classifiers = [s.split('=')[1] for m in meta_prep for s in m if s.startswith('s=')]\n",
    "classifiers = [str(int(c)-1) for c in classifiers]\n",
    "classifiers_np = np.asarray(classifiers)\n",
    "classifiers_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing\n",
    "# 1. 2 traces should be transposed and merged in 1 sample point\n",
    "traces_np = traces_np.reshape(-1).reshape(2000, 1)\n",
    "# 2. classifiers should be stretched as the 1st half of the sample point is R1 and 2nd one is R2\n",
    "classifiers_np = np.repeat(classifiers_np, len(traces_np)/2).reshape(2000, 1)\n",
    "# traces_np[:4], classifiers_np[:4]\n",
    "traces_np.shape, classifiers_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_value = 1e-300\n",
    "tvla_thrd = 4.5 * np.sqrt(2)\n",
    "\n",
    "PROJECT_ROOT_DIR=os.getcwd()\n",
    "tracenum = 50*1000\n",
    "step = 50\n",
    "sample_start = 120 # 30  100    # 40\n",
    "sample_end =   130 # 50  500    # 180\n",
    "rlen = sample_end - sample_start\n",
    "\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "if not os.path.exists(IMAGES_PATH): os.makedirs(IMAGES_PATH)\n",
    "\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT_DIR, \"log\")\n",
    "if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check. Make sure it leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrace = np.mean(traces_np[:10], axis=0)\n",
    "tt = tests.fvr_ttest(traces_np, classifiers_np)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_ylabel('voltage', color='g')\n",
    "ax1.tick_params(axis='y', labelcolor='g')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('leakage', color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "ax1.plot(atrace, color='g') # signal\n",
    "ax2.plot(tt, color='r')     # leak\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6c7c5910d8ec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-6c7c5910d8ec>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ALL DONE TILL THIS POINT\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ALL DONE TILL THIS POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstat_evo = []\n",
    "cnt = 1\n",
    "xx = np.arange(step, tracenum+1, step)\n",
    "for x in xx:\n",
    "    start = time.time()\n",
    "    tt = tests.fvr_ttest(data_np[:x], classifiers_np[:x])\n",
    "    if cnt % 200 == 0:\n",
    "        print(\"Trace count: {}, done in {}\".format(x, time.time() - start))\n",
    "    cnt += 1\n",
    "    tstat_evo.append(tt)\n",
    "tstat_evo = np.array(tstat_evo)\n",
    "tstat_evo = np.abs(tstat_evo) # comment out for intermediates\n",
    "\n",
    "# Max leakage info\n",
    "tr_num, max_leak_pt = np.unravel_index(np.argmax(tstat_evo), tstat_evo.shape)\n",
    "max_leak_val, max_leak_at = tstat_evo[tr_num, max_leak_pt], tr_num*step\n",
    "max_leak_pv = tdist.sf(max_leak_val, max_leak_at)\n",
    "print(\"Max leak at point: {}, value: {:5.3e} (pv: {:5.3e}), trace: {}\".format(\n",
    "    max_leak_pt, max_leak_val, max_leak_pv, max_leak_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_num, pt_num = np.shape(tstat_evo)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.ylabel('T score')\n",
    "plt.xlabel('Trace Number')\n",
    "plt.axhline(y=tvla_thrd, color='r', linestyle=':')\n",
    "\n",
    "x_axis = np.arange(step_num) * step\n",
    "\n",
    "# Plot leak history for each 2nd point\n",
    "for j in range(0, pt_num, 2):\n",
    "    plk = tstat_evo.T[j]\n",
    "    plt.plot(x_axis, plk, linewidth=0.5, linestyle='-', color = 'grey', zorder = j)\n",
    "\n",
    "# Max leak point\n",
    "mlpt = max_leak_pt\n",
    "plt.plot(x_axis, tstat_evo[:, mlpt], linewidth=1, linestyle='-', color = 'r', zorder=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boots_list = [11, 21, 51]  # boots\n",
    "boot_step = 200   # step\n",
    "upper_bnd = 250 #tracenum\n",
    "ld_stat = stats.uniform\n",
    "ld_cdf = ld_stat().cdf\n",
    "\n",
    "t_full_per_step = []   # cannot be numpy array due to different lengths per boot\n",
    "tp_full_per_step = []  # cannot be numpy array due to different lengths per boot\n",
    "ksp_per_step = []\n",
    "for rangenum in range(boot_step, upper_bnd+1, boot_step):\n",
    "    # Run all boots for a step\n",
    "    t_full_per_boot, tp_full_per_boot, ksp_per_boot = [], [], []\n",
    "    for j, boots in enumerate(boots_list):\n",
    "        start = time.time()\n",
    "        crossed_ml = 0\n",
    "        t_full = np.empty((boots, rlen), dtype=np.float64)\n",
    "        tp_full = np.empty_like(t_full)\n",
    "        ks_full = np.empty_like(tp_full[0])\n",
    "        boot_idxs = np.random.randint(rangenum, size=(boots, rangenum))\n",
    "        for i, bi in enumerate(boot_idxs):\n",
    "            t_full[i] = tests.fvr_ttest(data_np[bi], classifiers_np[bi]) # calc tt and keep it\n",
    "            tp_full[i] = tdist.sf(t_full[i], rangenum)                   # convert tt to pv and keep pv\n",
    "        # Run ks-test for p-values as the post process boot for the step\n",
    "        for i in range(rlen):\n",
    "            d, ks_full[i] = f.kstest(tp_full.T[i], ld_cdf)               # throw away d, keep pv\n",
    "        t_full_per_boot.append(t_full)\n",
    "        tp_full_per_boot.append(tp_full)\n",
    "        ksp_per_boot.append(ks_full)\n",
    "#         lfound = 'SAME LEAK ACHIEVED!' if ks_full[max_leak_pt] < max_leak_pv else ''\n",
    "#         print(\"Trace count: {}, boots: {} are done in {} ({})\".format(\n",
    "#             rangenum, boots, time.time() - start, lfound))\n",
    "    t_full_per_step.append(t_full_per_boot)\n",
    "    tp_full_per_step.append(tp_full_per_boot)\n",
    "    ksp_per_step.append(ksp_per_boot)\n",
    "ksp_per_step = np.asarray(ksp_per_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ksp_per_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpi =  max_leak_pt # 15\n",
    "\n",
    "# Prepare data\n",
    "ksp_per_step[np.where(np.isnan(ksp_per_step))] = small_value\n",
    "ksp_per_step[np.where(ksp_per_step < small_value)] = small_value\n",
    "\n",
    "pt_num, step_num = np.shape(ksp_per_step[:, 0].T)\n",
    "\n",
    "x_axis = (np.arange(step_num) + 1) * boot_step\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Trace Number')\n",
    "plt.ylabel('ks: -log10(pv)')\n",
    "# tvla_high threshold converted to pv scale\n",
    "tvla_thrd_pvlog = -np.log10(max_leak_pv) # 200 is approx n\n",
    "plt.axhline(y=tvla_thrd_pvlog, color='r', linestyle=':')\n",
    "\n",
    "# Plot boot evolution for each 2nd point of 1st boot in the list (for comparison)\n",
    "boot_idx = 0\n",
    "plot_evo = ksp_per_step[:, boot_idx].T\n",
    "for j in range(0, pt_num, 2):\n",
    "    kspl = -np.log10(plot_evo[j])\n",
    "    plt.plot(x_axis, kspl, linewidth=0.75, color = 'grey', zorder = j)\n",
    "\n",
    "# and hist for max leaky point per boot\n",
    "cpalette = ['b', 'y', 'g', 'r', 'c']\n",
    "for i in range(ksp_per_step.shape[1]):\n",
    "    maxkslpv = -np.log10(ksp_per_step[:, i].T[mlpi])  # boots_list[0]\n",
    "    plt.plot(x_axis, maxkslpv, linewidth=1.5, color = cpalette[i%5], zorder=255)\n",
    "\n",
    "plt.show()\n",
    "# plot_evo.shape, x_axis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Real threshold is 4.5 * sqrt(2) is similar to twice as much traces (TVLA requires two runs). \n",
    "- It means that leak is not occasional\n",
    "- The threshold get converted to t-distribution p-value to compare with ks-test p-value\n",
    "- We can compare (number_of_traces1) required to reach the point of the real leakage with (number_of_boots) * (number_of_traces2). Where number_of_traces1 is the number for the regular TVLA process and (number_of_traces2) is the number required for bootstrapping.\n",
    "  - For example TVLA requires 43.5k traces to reach 6 sigma, bootstrapping requires 225 traces * 50 boots = 11250, i.e. bootstrapping reaches the same leak *4 times faster*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are cells to debug code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging ks-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find out whether it follows the uniform distribution\n",
    "ksp_per_step2 = np.zeros_like(tp_full_per_step[:,1])\n",
    "\n",
    "for s, bps in enumerate(tp_full_per_step):          # step\n",
    "    bpsr = bps.T                                    # -> (pt, boot)\n",
    "    start = time.time()\n",
    "    print('{}: Step {} ...'.format(bpsr.shape, s))\n",
    "    for i, ptbt in enumerate(bpsr):\n",
    "        d, kpv = f.kstest(ptbt, ld_cdf)\n",
    "        ksp_per_step2[s, i] = kpv\n",
    "    print(\"Done in {}\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging distributions for kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mpi = max_leak_pt # 6 178\n",
    "si = 2\n",
    "\n",
    "# bpvs = t_full_per_step[si].T  # t\n",
    "bpvs = tp_full_per_step[si].T   # t-pv\n",
    "\n",
    "kpvs = []\n",
    "leak_dist = stats.uniform\n",
    "# leak_dist = stats.norm\n",
    "for j in range(0, len(bpvs)):\n",
    "    bp = bpvs[j]\n",
    "    d, pv = f.kstest(bp, leak_dist().cdf)\n",
    "    l, s = leak_dist.fit(bp)      # loc and scale of the dist at the point\n",
    "    leaking = pv < 0.05           # 3 sigma assurance the point is leaking (non uniform)\n",
    "    kpvs.append([d, pv, l, s, leaking])\n",
    "d, pv = f.kstest(bpvs[mpi], leak_dist().cdf)\n",
    "l, s = leak_dist.fit(bpvs[mpi])  # loc and scale of the dist at the max leak point\n",
    "leaking = pv < 0.05\n",
    "kpvs.append([d, pv, l, s, leaking])\n",
    "\n",
    "# print(\"d, pv, l, s, leaking\")\n",
    "# print(np.array(kpvs))\n",
    "    \n",
    "# norm_cdf = norm(loc=0, scale=1).cdf\n",
    "# dt, pv  = stats.kstest(bpvs, norm_cdf)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Boot Number')\n",
    "for j in range(0, len(bpvs), 20):\n",
    "    plt.plot(bpvs[j], color = 'grey', linewidth=0.5, zorder = j)\n",
    "\n",
    "plt.plot(bpvs[mpi], color = 'r', linewidth=2, zorder=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging at some boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script false    # This line is to skip this cell as a whole in the real run. Comment to debug a boot step\n",
    "# rp_full_per_step = []  # rpv\n",
    "# t_full_per_step = []   # t\n",
    "# tp_full_per_step = []  # tpv\n",
    "\n",
    "pb = 0\n",
    "bootidx = 15\n",
    "\n",
    "pb = 0\n",
    "pi = 19 #byte_pt[pb]\n",
    "bi = byte_idx[pb]\n",
    "hwi = key_idx[pb]   # kpv = 0\n",
    "\n",
    "plot_evo = t_full_per_step[:,bootidx,:,pi].reshape(-1, 3, 256)\n",
    "\n",
    "x_axis = (np.arange(len(plot_evo)) + 1) * step\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Trace Number')\n",
    "plt.ylabel('T score')\n",
    "\n",
    "hw_num = plot_evo.shape[2]\n",
    "for j in range(0, hw_num, 4):\n",
    "    mtt = plot_evo[:, byte_idx[pb], j]\n",
    "    plt.plot(x_axis, mtt, linewidth=0.5, color = 'grey', zorder = j)\n",
    "plt.plot(x_axis, plot_evo[:, byte_idx[pb], key_idx[pb]], linewidth=1, color = 'r', zorder=255)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = uniform(loc=0, scale=1)\n",
    "for i in range(3):\n",
    "    udrv = ud.rvs(size=1000)\n",
    "    dk, kpv = stats.kstest(udrv, 'uniform') # H0 - data is uniform\n",
    "    non_uniform = kpv < 0.05\n",
    "    print(dk, kpv, non_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_100 = norm.rvs(loc=10, scale=1, size=100)\n",
    "nd = norm(loc=0, scale=1)\n",
    "for i in range(3):\n",
    "    ndrv = nd.rvs(size=100)\n",
    "    dn, npv = stats.kstest(ndrv, 'norm') # H0 - data is norm\n",
    "    non_norm = npv < 0.05\n",
    "    print(dn, npv, non_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_cdf = norm(loc=10, scale=1).cdf\n",
    "for i in range(3):\n",
    "    ndrv = norm.rvs(loc=10, scale=1, size=100)\n",
    "    dn, npv = stats.kstest(ndrv, nd_cdf) # H0 - data is norm\n",
    "    non_norm = npv < 0.05\n",
    "    print(dn, npv, non_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
